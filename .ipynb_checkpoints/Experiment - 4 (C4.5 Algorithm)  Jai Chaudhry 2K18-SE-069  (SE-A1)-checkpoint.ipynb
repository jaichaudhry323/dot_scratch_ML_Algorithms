{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Jai Chaudhry 2K18-SE-069`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment - 3\n",
    "\n",
    "- Write a program to exhibit the working of the decision tree based ID3 algorithm. \n",
    "- With the help of appropriate data set build the decision tree and classify a new sample.\n",
    "- Then Finding Accuracy, Precision, Recall and ROC_AUC Score of the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "eps = np.finfo(float).eps\n",
    "from numpy import log2 as log\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Entropy of DataFrame `Df` for a subtree:\n",
    "def find_entropy(df): \n",
    "    Class = df.keys()[-1]           \n",
    "    entropy = 0\n",
    "    values = df[Class].unique()\n",
    "    for value in values:\n",
    "        fraction = df[Class].value_counts()[value]/len(df[Class])\n",
    "        entropy += -fraction * np.log2(fraction)\n",
    "    return entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find entropy of dataframe wrt a certain attribute\n",
    "def find_entropy_attribute(df,attribute):\n",
    "    Class = df.keys()[-1]                \n",
    "    \n",
    "    target_variables = df[Class].unique() \n",
    "    variables = df[attribute].unique()    \n",
    "    entropy2 = 0\n",
    "    \n",
    "    for variable in variables:\n",
    "        entropy = 0\n",
    "        den = len(df[attribute][df[attribute]==variable])\n",
    "        \n",
    "        for target_variable in target_variables:\n",
    "            num = len(df[attribute][df[attribute]==variable][df[Class] == target_variable])\n",
    "            fraction = num/(den+eps)\n",
    "            entropy += -fraction*log(fraction+eps)\n",
    "            \n",
    "        fraction2 = den/len(df)\n",
    "        entropy2 += fraction2*entropy\n",
    "    \n",
    "    return abs(entropy2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get The one that is the best divider for current node\n",
    "def find_winner(df):\n",
    "    Entropy_att = []\n",
    "    IG = []\n",
    "    for key in df.keys()[:-1]:\n",
    "        IG.append(find_entropy(df)-find_entropy_attribute(df,key))\n",
    "\n",
    "    return df.keys()[:-1][np.argmax(IG)]                                \n",
    "\n",
    "\n",
    "## Get the subset of data that has a specific attr.'s value as x \n",
    "def get_subtable(df, node ,value): \n",
    "    return df[df[node] == value].reset_index(drop=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Driver Function to create Tree\n",
    "def buildTree(df,TgtClass,previous_winner=0,tree=None): \n",
    "    Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
    "    \n",
    "    # Here we build our decision tree\n",
    "    \n",
    "    # Get attribute with maximum information gain\n",
    "    node = find_winner(df)\n",
    "    \n",
    "    print(node)\n",
    "    \n",
    "    # Create an empty dictionary to create tree    \n",
    "    if tree is None:                    \n",
    "        tree={}\n",
    "        tree[node] = {}\n",
    "    \n",
    "    if previous_winner == node:\n",
    "        clValue,counts = np.unique(df[TgtClass],return_counts = True) \n",
    "        tree[node][df[node][0]] = clValue[np.argmax(counts)]\n",
    "        return tree\n",
    "    \n",
    "    # Get distinct value of that attribute e.g Salary is node and Low,Med and High are values\n",
    "    attValue = np.unique(df[node])\n",
    "\n",
    "   # We make loop to construct a tree by calling this function recursively. \n",
    "   # In this we check if the subset is pure and stops if it is pure. \n",
    "    \n",
    "    for value in attValue:\n",
    "        \n",
    "        subtable = get_subtable(df,node,value)\n",
    "        clValue,counts = np.unique(subtable[TgtClass],return_counts = True)   \n",
    "        \n",
    "        if len(counts) == 1:                                                   # Checking purity of subset\n",
    "            tree[node][value] = clValue[0]   \n",
    "        else:        \n",
    "            tree[node][value] = buildTree(subtable,TgtClass,node)            # Calling the function recursively \n",
    "                   \n",
    "    return tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Dataset : (Sample Class Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>weak</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>strong</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>overcast</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>weak</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>rain</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>weak</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>rain</td>\n",
       "      <td>cold</td>\n",
       "      <td>normal</td>\n",
       "      <td>weak</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outlook  temp humidity   windy play\n",
       "0     sunny   hot     high    weak   no\n",
       "1     sunny   hot     high  strong   no\n",
       "2  overcast   hot     high    weak  yes\n",
       "3      rain  mild     high    weak  yes\n",
       "4      rain  cold   normal    weak  yes"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlook = 'sunny,sunny,overcast,rain,rain,rain,overcast,sunny,sunny,rain,sunny,overcast,overcast,rain'.split(',')\n",
    "temp='hot,hot,hot,mild,cold,cold,cold,mild,cold,mild,mild,mild,hot,mild'.split(',')\n",
    "humidity = 'high,high,high,high,normal,normal,normal,high,normal,normal,normal,high,normal,high'.split(',')\n",
    "windy = 'weak,strong,weak,weak,weak,strong,strong,weak,weak,weak,strong,strong,weak,strong'.split(',')\n",
    "play = 'no,no,yes,yes,yes,no,yes,no,yes,yes,yes,yes,yes,no'.split(',')\n",
    "\n",
    "dataset=0\n",
    "\n",
    "dataset = {'outlook':outlook,'temp':temp,'humidity':humidity,'windy':windy,'play':play}\n",
    "df = pd.DataFrame(dataset,columns=['outlook','temp','humidity','windy','play'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlook\n",
      "windy\n",
      "humidity\n",
      "{'outlook': {'overcast': 'yes',\n",
      "             'rain': {'windy': {'strong': 'no', 'weak': 'yes'}},\n",
      "             'sunny': {'humidity': {'high': 'no', 'normal': 'yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "t = buildTree(df,'play')\n",
    "\n",
    "import pprint      \n",
    "pprint.pprint(t)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "\n",
    "dict = {}\n",
    "\n",
    "def draw(parent_name, child_name):\n",
    "    edge = pydot.Edge(parent_name, child_name)\n",
    "    graph.add_edge(edge)\n",
    "\n",
    "\n",
    "def visit(node, parent=None):\n",
    "    for k,v in node.items():\n",
    "        if isinstance(v, type(dict)):\n",
    "            # We start with the root node whose parent is None\n",
    "            # we don't want to graph the None node\n",
    "            if parent:\n",
    "                draw(parent, k)\n",
    "            visit(v, k)\n",
    "            \n",
    "        else:\n",
    "            draw(parent, k)\n",
    "            # drawing the label using a distinct name\n",
    "            draw(k, k+'_'+v)\n",
    "\n",
    "\n",
    "graph = pydot.Dot(graph_type='graph')\n",
    "\n",
    "visit(t)\n",
    "\n",
    "graph.write_png('Play_Tennis_ID3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Play_Tennis_ID3.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Implementing Decision Tree on Adult DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy \n",
    "import pandas as pd\n",
    "\n",
    "def get_processed_data():\n",
    "\n",
    "    data = pd.read_csv('C:\\\\Users\\\\Jai\\\\Desktop\\\\adult.csv',na_values='?')\n",
    "\n",
    "    num_cols = list(data.select_dtypes(include=[\"number\"]).columns)\n",
    "    cat_cols = list(data.select_dtypes(exclude=[\"number\"]).columns)\n",
    "    \n",
    "    ## Drop NaN valued tuples\n",
    "    data = data.dropna() \n",
    "    data.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    print(type(data))\n",
    "    \n",
    "    ndata = data.select_dtypes(include=['number']) \n",
    "    cdata = data.select_dtypes(exclude=['number']) \n",
    "\n",
    "    # Categorical to Numerical\n",
    "    cols = ndata.columns\n",
    "    b = np.array(ndata)\n",
    "    a = np.array(ndata,dtype=object)\n",
    "    print(a.shape)\n",
    "\n",
    "    for i in range(0,len(cols)):\n",
    "\n",
    "        col = cols[i]\n",
    "        meann = np.round(ndata[col].mean())\n",
    "\n",
    "        for j in range(0,len(ndata)):\n",
    "            if b[j][i] >= meann:\n",
    "                a[j][i] = \">=\" + str(meann)\n",
    "            else:\n",
    "                a[j][i] = \"<\" + str(meann)\n",
    "\n",
    "\n",
    "    newdata = pd.DataFrame(a).applymap(str)\n",
    "    ndata = newdata\n",
    "    ndata.columns = cols\n",
    "    \n",
    "    ### Merging the Transformed Numeric Data with Categorical Data\n",
    "    ndata.reset_index(drop=True, inplace=True)\n",
    "    cdata.reset_index(drop=True,inplace=True)\n",
    "    frames = [ndata,cdata]\n",
    "    result = pd.concat(frames,axis = 1)\n",
    "    \n",
    "    ### Final DataFrame after Processing\n",
    "    data =  result\n",
    "    \n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(45222, 6)\n"
     ]
    }
   ],
   "source": [
    "data = get_processed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_size 2261\n",
      "Test_size 42961\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.95\n",
    "train_size = int((1 - test_size)* len(data))\n",
    "\n",
    "df_train = data[:train_size]\n",
    "df_test = data[train_size:]\n",
    "\n",
    "df_test.reset_index(drop=True)\n",
    "df_train.reset_index(drop=True)\n",
    "\n",
    "print(\"Train_size\",len(df_train))\n",
    "print(\"Test_size\",len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.applymap(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relationship\n",
      "education\n",
      "occupation\n",
      "age\n",
      "workclass\n",
      "age\n",
      "age\n",
      "hours-per-week\n",
      "fnlwgt\n",
      "age\n",
      "age\n",
      "occupation\n",
      "age\n",
      "workclass\n",
      "hours-per-week\n",
      "hours-per-week\n",
      "occupation\n",
      "occupation\n",
      "capital-gain\n",
      "capital-gain\n",
      "occupation\n",
      "fnlwgt\n",
      "hours-per-week\n",
      "occupation\n",
      "capital-loss\n",
      "fnlwgt\n",
      "fnlwgt\n",
      "capital-gain\n",
      "occupation\n",
      "workclass\n",
      "workclass\n",
      "age\n",
      "age\n",
      "fnlwgt\n",
      "occupation\n",
      "capital-gain\n",
      "race\n",
      "workclass\n",
      "age\n",
      "capital-loss\n",
      "age\n",
      "fnlwgt\n",
      "capital-gain\n",
      "fnlwgt\n",
      "hours-per-week\n",
      "fnlwgt\n",
      "occupation\n",
      "hours-per-week\n",
      "workclass\n",
      "age\n",
      "fnlwgt\n",
      "native-country\n",
      "age\n",
      "workclass\n",
      "capital-gain\n",
      "hours-per-week\n",
      "fnlwgt\n",
      "age\n",
      "age\n",
      "fnlwgt\n",
      "hours-per-week\n",
      "workclass\n",
      "capital-gain\n",
      "capital-loss\n",
      "race\n",
      "age\n",
      "fnlwgt\n",
      "age\n",
      "age\n",
      "age\n",
      "age\n",
      "age\n",
      "capital-gain\n",
      "age\n",
      "fnlwgt\n",
      "capital-gain\n",
      "capital-loss\n",
      "fnlwgt\n",
      "workclass\n",
      "native-country\n",
      "age\n",
      "age\n",
      "age\n",
      "age\n",
      "age\n",
      "hours-per-week\n",
      "workclass\n",
      "age\n",
      "age\n",
      "age\n",
      "fnlwgt\n",
      "native-country\n",
      "capital-gain\n",
      "capital-loss\n",
      "hours-per-week\n",
      "age\n",
      "fnlwgt\n",
      "age\n",
      "age\n",
      "age\n",
      "age\n",
      "age\n",
      "age\n",
      "fnlwgt\n",
      "race\n",
      "age\n",
      "capital-gain\n",
      "capital-loss\n",
      "age\n",
      "hours-per-week\n",
      "workclass\n",
      "age\n",
      "age\n",
      "workclass\n",
      "fnlwgt\n",
      "hours-per-week\n",
      "age\n",
      "age\n",
      "hours-per-week\n",
      "age\n",
      "age\n",
      "fnlwgt\n",
      "age\n",
      "age\n",
      "hours-per-week\n",
      "fnlwgt\n",
      "workclass\n",
      "fnlwgt\n",
      "hours-per-week\n",
      "age\n",
      "age\n",
      "fnlwgt\n",
      "hours-per-week\n",
      "workclass\n",
      "native-country\n",
      "workclass\n",
      "fnlwgt\n",
      "capital-loss\n",
      "age\n",
      "age\n",
      "fnlwgt\n",
      "fnlwgt\n",
      "occupation\n",
      "workclass\n",
      "fnlwgt\n",
      "capital-gain\n",
      "hours-per-week\n",
      "age\n",
      "age\n",
      "workclass\n",
      "age\n",
      "hours-per-week\n",
      "fnlwgt\n",
      "capital-gain\n",
      "native-country\n",
      "age\n",
      "age\n",
      "capital-gain\n",
      "fnlwgt\n",
      "age\n",
      "age\n",
      "fnlwgt\n",
      "hours-per-week\n",
      "age\n",
      "age\n",
      "capital-gain\n",
      "race\n",
      "capital-loss\n",
      "hours-per-week\n",
      "age\n",
      "age\n",
      "age\n",
      "age\n",
      "age\n",
      "native-country"
     ]
    }
   ],
   "source": [
    "tree = buildTree(df_train,'income')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree,prev,sample,cnt):\n",
    "    \n",
    "    # Find the current attr / parameter\n",
    "    # Check the value of that in sample\n",
    "    # Then navigate through the tree accordingly\n",
    "    \n",
    "#     global err, exception, returning\n",
    "    \n",
    "    if cnt > limit:\n",
    "#         err += 1\n",
    "        return \"idk\"\n",
    "    try:\n",
    "        tkeys = list(tree.keys())\n",
    "    except:\n",
    "        return tree\n",
    "    \n",
    "    try:\n",
    "        if len(tkeys)==1:\n",
    "            # Found a category\n",
    "            t=1\n",
    "            return predict(tree[tkeys[0]],tkeys[0],sample,cnt+1)\n",
    "        else:\n",
    "            return predict(tree[sample[prev]],\"-1\",sample,cnt+1)\n",
    "    except:\n",
    "#         exception += 1\n",
    "        return \"idk\"\n",
    "    \n",
    "#     returning += 1\n",
    "    return \"idk\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(preds,actual):\n",
    "    \n",
    "    # first converting to 0 / 1\n",
    "    predictions = np.zeros(len(preds))\n",
    "    y_actual = np.zeros(len(actual))\n",
    "    \n",
    "    print(len(actual))\n",
    "    \n",
    "    for i in range(0,len(actual)):\n",
    "        if preds[i]=='>50K':\n",
    "            predictions[i] = 1\n",
    "            \n",
    "        if actual[i]=='>50K':\n",
    "            y_actual[i] = 1\n",
    "    \n",
    "#     print(y_actual)\n",
    "#     print(predictions)\n",
    "    \n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y_actual,predictions)*100\n",
    "    print('Accuracy      : %f' % (accuracy),\"%\")\n",
    "\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_actual,predictions)*100\n",
    "    print('Precision     : %f' % precision,\"%\")\n",
    "\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_actual,predictions)*100\n",
    "    print('Recall        : %f' % recall,\"%\")\n",
    "\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_actual,predictions)*100\n",
    "    print('F1 score      : %f' % f1,\"%\")\n",
    "\n",
    "    # ROC AUC\n",
    "    auc = roc_auc_score(y_actual,predictions)*100\n",
    "    print(\"roc_auc_score :\",auc,\"%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "df_test = df_train[:1000]\n",
    "print(len(df_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = np.array(df_test.iloc[:,-1])\n",
    "preds = []\n",
    "\n",
    "for i in range(0,len(df_test)):\n",
    "    try:\n",
    "        preds.append(predict(tree,\"-1\",df_test.iloc[i].to_dict(),0))\n",
    "    except:\n",
    "        preds.append(\"idk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "Accuracy      : 75.000000 %\n",
      "Precision     : 0.000000 %\n",
      "Recall        : 0.000000 %\n",
      "F1 score      : 0.000000 %\n",
      "roc_auc_score : 50.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jai\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print_metrics(preds,y_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
